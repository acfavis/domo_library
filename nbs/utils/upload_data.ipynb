{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: utils.upload_data.html\n",
    "title: Upload Data to Domo\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils.upload_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "import httpx\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "\n",
    "import domolibrary.client.Logger as lc\n",
    "import domolibrary.client.DomoAuth as dmda\n",
    "import domolibrary.classes.DomoDataset as dmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def upload_data(instance_auth : dmda.DomoAuth, # instance where the data_fn function will execute against\n",
    "                      consol_auth : dmda.DomoAuth, # instance where the data should be accumulated\n",
    "                      consol_ds : dmds.DomoDataset, \n",
    "                      partition_key: str, \n",
    "                      data_fn : callable,\n",
    "                      is_index: bool = False,\n",
    "                      debug_prn: bool = False,\n",
    "                      debug_api:bool = False,\n",
    "                      logger: lc.Logger = None):\n",
    "\n",
    "    try:\n",
    "        # await asyncio.sleep(randrange(5))\n",
    "        if logger : \n",
    "            logger.log_info (f\" Upload_data function - starting {instance_auth.domo_instance} - {data_fn.__name__}\")\n",
    "        if debug_prn:\n",
    "            print(\n",
    "                f\"starting {instance_auth.domo_instance} - {data_fn.__name__}\")\n",
    "\n",
    "        instance_session = httpx.AsyncClient()\n",
    "\n",
    "        upload_df = await data_fn(instance_auth, instance_session, debug_api = debug_api)\n",
    "\n",
    "        if upload_df is None or len(upload_df.index) == 0:\n",
    "            return None\n",
    "\n",
    "        await instance_session.aclose()\n",
    "\n",
    "        return await consol_ds.upload_data(upload_df=upload_df,\n",
    "                                          upload_method='REPLACE',\n",
    "                                          partition_key=partition_key,\n",
    "                                          is_index=False,\n",
    "                                          debug_api=debug_api,\n",
    "                                          debug_prn=debug_prn)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"upload_data : unexpected error: {e}\")\n",
    "        if logger : \n",
    "            logger.log_error(f\"upload_data : unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        await instance_session.aclose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_data_with_date(instance_auth,\n",
    "                                consol_auth,\n",
    "                                data_fn,\n",
    "                                consol_ds,\n",
    "                                partition_date_col,\n",
    "                                partition_delimiter,\n",
    "                                start_date,\n",
    "                                end_date,\n",
    "                                debug: bool = False,\n",
    "                                debug_prn: bool = False):\n",
    "\n",
    "    instance_session = httpx.AsyncClient()\n",
    "\n",
    "    print(\n",
    "        f\"'ðŸŽ¬ upload_with_data: starting retrieval {start_date}, {end_date}, {instance_auth.domo_instance}\")\n",
    "\n",
    "    upload_df = await data_fn(instance_auth=instance_auth,\n",
    "                              session=instance_session,\n",
    "                              start_date=start_date,\n",
    "                              end_date=end_date,\n",
    "                              debug=debug)\n",
    "\n",
    "    await instance_session.aclose()\n",
    "\n",
    "    if not isinstance(upload_df, pd.DataFrame):\n",
    "        print(f\"ðŸ›‘ error no data returned {instance_auth.domo_instance}\")\n",
    "        print(upload_df)\n",
    "        return None\n",
    "\n",
    "    if debug_prn:\n",
    "        print(\n",
    "            f'ðŸ§» upload_with_data: starting upload {len(upload_df)} rows for {instance_auth.domo_instance}')\n",
    "\n",
    "    task = []\n",
    "\n",
    "    for index, partition_set in upload_df.drop_duplicates(subset=[partition_date_col]).iterrows():\n",
    "        partition_date = partition_set[partition_date_col]\n",
    "\n",
    "        partition_key = f\"{instance_auth.domo_instance}{partition_delimiter}{str(partition_date)}\"\n",
    "\n",
    "        task.append(consol_ds.upload_data(upload_df=upload_df[(upload_df[partition_date_col] == partition_date)],\n",
    "                                          upload_method='REPLACE',\n",
    "                                          partition_key=partition_key,\n",
    "                                          is_index=False,\n",
    "                                          debug_api=debug_api,\n",
    "                                          debug_prn=debug_prn\n",
    "                                          ))\n",
    "\n",
    "    res = await asyncio.gather(*task)\n",
    "\n",
    "    if debug_prn:\n",
    "        print(\n",
    "            f'ðŸŽ‰ upload_with_data : finished uploading {len(upload_df)} rows for {instance_auth.domo_instance}')\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetNotProvidedError",
     "evalue": "upload_data: dataset_id not provided at domo-dojo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatasetNotProvidedError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m ds \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m dmds\u001b[39m.\u001b[39mDomoDataset\u001b[39m.\u001b[39mget_from_id( dataset_id \u001b[39m=\u001b[39m ds_id , auth \u001b[39m=\u001b[39m token_auth )\n\u001b[1;32m     11\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([{\u001b[39m\"\u001b[39m\u001b[39mcol_a\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcol_b\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcol_c\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mc\u001b[39m\u001b[39m\"\u001b[39m}])\n\u001b[0;32m---> 13\u001b[0m \u001b[39mawait\u001b[39;00m ds\u001b[39m.\u001b[39mupload_data( upload_df \u001b[39m=\u001b[39m df)\n",
      "File \u001b[0;32m/workspaces/domo_library/domolibrary/classes/DomoDataset.py:524\u001b[0m, in \u001b[0;36mupload_data\u001b[0;34m(self, upload_df, upload_df_ls, upload_file, upload_method, partition_key, is_index, dataset_id, dataset_upload_id, auth, session, debug_api, debug_prn)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39m@patch_to\u001b[39m(DomoDataset)\n\u001b[1;32m    504\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mupload_data\u001b[39m(\u001b[39mself\u001b[39m : DomoDataset,\n\u001b[1;32m    505\u001b[0m                       upload_df: pd\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m                       debug_prn: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    522\u001b[0m                       ):\n\u001b[0;32m--> 524\u001b[0m     auth, dataset_id \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m _have_prereqs(\u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m, auth \u001b[39m=\u001b[39m auth, dataset_id\u001b[39m=\u001b[39mdataset_id, function_name\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mupload_data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    526\u001b[0m     upload_df_ls \u001b[39m=\u001b[39m upload_df_ls \u001b[39mor\u001b[39;00m [upload_df]\n\u001b[1;32m    528\u001b[0m     status_message \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdataset_id\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mpartition_key\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mauth\u001b[39m.\u001b[39mdomo_instance\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/workspaces/domo_library/domolibrary/classes/DomoDataset.py:67\u001b[0m, in \u001b[0;36m_have_prereqs\u001b[0;34m(self, auth, dataset_id, function_name)\u001b[0m\n\u001b[1;32m     64\u001b[0m dataset_id \u001b[39m=\u001b[39m dataset_id \u001b[39mor\u001b[39;00m parent_ds_id\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dataset_id:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mraise\u001b[39;00m de\u001b[39m.\u001b[39mDatasetNotProvidedError(\n\u001b[1;32m     68\u001b[0m         function_name \u001b[39m=\u001b[39m function_name, \n\u001b[1;32m     69\u001b[0m         domo_instance \u001b[39m=\u001b[39m auth\u001b[39m.\u001b[39mdomo_instance\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     72\u001b[0m \u001b[39mreturn\u001b[39;00m auth, dataset_id\n",
      "\u001b[0;31mDatasetNotProvidedError\u001b[0m: upload_data: dataset_id not provided at domo-dojo"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-dojo\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "ds_id = 'cbae0e0c-a92d-4a4c-8d0c-c9ccd38fe928'\n",
    "\n",
    "ds = await dmds.DomoDataset.get_from_id( dataset_id = ds_id , auth = token_auth )\n",
    "\n",
    "df = pd.DataFrame([{\"col_a\" : \"a\", \"col_b\": \"b\", \"col_c\": \"c\"}])\n",
    "\n",
    "await ds.upload_data( upload_df = df)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
